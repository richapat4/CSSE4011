{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client, os, time\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision, WriteOptions\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from flightsql import FlightSQLClient\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"whl_f4m7pZbnLdO6KHYmNFjFdJaGimywqZXMezcOCwFcwJyUOW0nomnbHXzMdrxf3TeKOGbzpUW4B2rDXgUu5Q==\"\n",
    "org = \"csse4011\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "bucket=\"Demo_data\"\n",
    "\n",
    "write_client = influxdb_client.InfluxDBClient(url=url, token=token, org=org, debug=False)\n",
    "\n",
    "write_api = write_client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "point = (\n",
    "    Point(\"Position\")\n",
    "    .field(\"X\", 0)\n",
    "    .field(\"Y\", 0)\n",
    "    .field(\"Z\", 0)\n",
    "    .field(\"Velocity\", 2)\n",
    "    )\n",
    "write_api.write(bucket=bucket, org=\"csse4011\", record=point)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  8 12 15 18]\n",
      "[ 8 13 20 26 31]\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Combine the x and y coordinates into a single array\n",
    "data = np.vstack((x, y))\n",
    "\n",
    "# Apply Gaussian smoothing with a specified sigma (smoothing factor)\n",
    "sigma = 1.0\n",
    "smoothed_data = gaussian_filter(data, sigma=sigma)\n",
    "\n",
    "# Separate the smoothed data back into x and y coordinates\n",
    "smoothed_x = smoothed_data[0, :]\n",
    "smoothed_y = smoothed_data[1, :]\n",
    "\n",
    "# Print the smoothed coordinates\n",
    "print(smoothed_x)\n",
    "print(smoothed_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import signal\n",
    "import sys\n",
    "\n",
    "import influxdb_client, os, time\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision, WriteOptions\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from flightsql import FlightSQLClient\n",
    " \n",
    "from datetime import datetime\n",
    "from View2 import View\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.artist import Artist\n",
    "\n",
    "MAX_CSVS = 10\n",
    "WRITE_GAP = 1\n",
    "TEST_SAMPLES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.2\n",
    "\n",
    "# Apply clustering algorithm\n",
    "def clustering(self, testData):\n",
    "\n",
    "    center_df = pd.DataFrame({'X': [0],'Y': [0],'Z': [0], 'label':[0]})\n",
    "    separated_cluster = []\n",
    "    total_cluster = pd.DataFrame({'X': 0, 'Y': 0, 'Z': 0,'cluster_num': 0}, index=[0])\n",
    "\n",
    "\n",
    "    if(len(testData) > 0):\n",
    "\n",
    "        data = testData.copy()\n",
    "        x = data['X']\n",
    "        y = data['Y']\n",
    "        data = np.vstack((x, y))\n",
    "\n",
    "        sigma = 1.0\n",
    "        smoothed_data = gaussian_filter(data, sigma=sigma)\n",
    "\n",
    "        # Create a db clustering algorithm\n",
    "        db = DBSCAN(eps=EPSILON, min_samples=5).fit(smoothed_data)\n",
    "        labels = db.labels_ \n",
    "\n",
    "        # What shape is the dictionary in that allows it to be accessed this way?\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise_ = list(labels).count(-1)\n",
    "\n",
    "        # print(\"{0} {1}\".format(n_clusters_, len(self.testData)))\n",
    "        # print(self.testData)\n",
    "\n",
    "        center_df = pd.DataFrame({'X': [0],'Y': [0],'Z': [0], 'label':[0]})\n",
    "\n",
    "        for cluster_label in range(n_clusters_):\n",
    "\n",
    "            # Iterate through, assign each point to a cluster and find the centre point of each\n",
    "            # This is only going to return a two-dimensional array, which is no good\n",
    "            cluster_points = smoothed_data[labels == cluster_label]\n",
    "            cluster_points = cluster_points.assign(cluster_num=cluster_label)\n",
    "\n",
    "            for _, row in cluster_points.iterrow():\n",
    "                testRow = testData[testData[\"X\"] == row['X'] and testData['Y'] == row['Y']]\n",
    "                testRow['cluster_num'] = row['cluster_num']\n",
    "                total_cluster = pd.concat([total_cluster, testRow], axis=0)\n",
    "\n",
    "            # merged_df = pd.merge(cluster_points, testData, left_on=['X', 'Y'], right_on=['X', 'Y'], how='inner')\n",
    "            # matching_rows = merged_df['X', 'Y']\n",
    "            # cluster_points = testData[testData.isin(matching_rows.values).all(axis=1)]\n",
    "\n",
    "            # total_cluster = pd.concat([total_cluster, cluster_points], axis=0)\n",
    "\n",
    "            center_point = np.mean(cluster_points, axis=0)\n",
    "\n",
    "            z_points = testData[testData['X'] > center_point['X'] - EPSILON and testData['X'] < center_point['X'] + EPSILON\n",
    "                                and testData['Y'] > center_point['Y'] - EPSILON and testData['Y'] < center_point['Y'] + EPSILON]\n",
    "            \n",
    "            z = z_points['Z'].mean()\n",
    "\n",
    "            entry = pd.Series({'X':center_point['X'], 'Y':center_point['Y'], 'Z':z, 'label':center_point['cluster_num']})\n",
    "            center_df.loc[len(center_df)] = entry\n",
    "\n",
    "\n",
    "            # These lines of code are an attempt to get the box grid working for up to five clusters\n",
    "            #  check, but hopefully it works\n",
    "            #----------------------------------------------------------------------------------------------\n",
    "\n",
    "            x1, x2, y1, y2, z1, z2 = cluster_points['X'].min(), cluster_points['X'].max(), \\\n",
    "                    cluster_points['Y'].min(), cluster_points['Y'].max(), \\\n",
    "                    cluster_points['Z'].min(), cluster_points['Z'].max()\n",
    "            \n",
    "            self.draw3DRectangle_update(x1, x2, y1, y2, z1, z2, cluster_label)\n",
    "\n",
    "        for i in range(n_clusters_, 5):\n",
    "            self.draw3DRectangle_update(0, 0, 0, 0, 0, 0, i)\n",
    "\n",
    "        #-------------------------------------------------------------------------------------------------\n",
    "            \n",
    "        \n",
    "        self.num_clusters = n_clusters_\n",
    "        self.cluster_points = center_df.drop(center_df.index[0])\n",
    "        self.separated_clusters = total_cluster.drop(total_cluster.index[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
